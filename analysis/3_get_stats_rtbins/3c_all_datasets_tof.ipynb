{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get stats on ToF datasets\n",
    "\n",
    "This notebook explains the delta values within an RT window via isotopologues, adducts and fragments.\n",
    "\n",
    "- How many are explained by probable fragments; num of features and khipus.\n",
    "- How many are explained by MS2 (top 5 spectra per cpd in MoNA)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import contextlib\n",
    "from matchms.importing import load_from_msp\n",
    "from khipu.extended import peaklist_to_khipu_list, export_empCpd_khipu_list\n",
    "from mass2chem.search import build_centurion_tree, find_all_matches_centurion_indexed_list\n",
    "\n",
    "sys.path.insert(0, '..')\n",
    "from mining import * "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Isotopologue and Adducts from Step2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pos\n",
    "isp_pos = [ (1.003355, '13C/12C', (0, 0.8)),\n",
    "                            (2.00671, '13C/12C*2', (0, 0.8)),\n",
    "                            (3.9948, '44Ca/40Ca', (0, 0.1)), # 2%\n",
    "                            (1.9970, '37Cl/35Cl', (0.1, 0.8)), # 24.24%\n",
    "                            ]\n",
    "\n",
    "asp_pos = [  # initial patterns are relative to M+H+\n",
    "                            (21.98194, 'Na/H'),\n",
    "                            (41.026549, 'ACN'),     # Acetonitrile\n",
    "                            (67.987424, 'NaCOOH'),\n",
    "                            (37.955882, 'K/H'),\n",
    "                            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neg \n",
    "isp_neg = [ (1.003355, '13C/12C', (0, 0.8)),\n",
    "                            (2.00671, '13C/12C*2', (0, 0.8)),\n",
    "                            (1.9970, '37Cl/35Cl', (0.1, 0.8)), # 24.24%\n",
    "                            ]\n",
    "\n",
    "asp_neg = [  # initial patterns are relative to M+H+\n",
    "                            (21.98194, 'Na/H'), (67.987424, 'NaCOOH'),\n",
    "                            (82.0030, 'C2HF3'),\n",
    "                            (1.99566, 'F <-> OH'), \n",
    "                            ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some Reused Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_in_rtwindow(list_features, rt_ref, rt_stdev):\n",
    "    '''returns features in list_features that are within rt_stdev\n",
    "    \n",
    "    list_features: full list of features\n",
    "    rt_ref: the reference retention time as the center of window\n",
    "    rt_stdev: tolerance of retention time selecting\n",
    "    \n",
    "    return: list of features inside the given window\n",
    "    '''\n",
    "    return [f for f in list_features if abs(f['rtime']-rt_ref) <= rt_stdev]   \n",
    "\n",
    "def get_khipus_in_rtwindow(list_khipus, rt_ref, rt_stdev):\n",
    "    '''returns khipus in list_khipus that are within rt_stdev\n",
    "    \n",
    "    list_khipus: given list of khipus\n",
    "    rt_ref: the reference retention time as the center of window\n",
    "    rt_stdev: tolerance of retention time selecting\n",
    "    \n",
    "    return: list of khipus inside the given window\n",
    "    '''\n",
    "    return [f for f in list_khipus if abs(f['MS1_pseudo_Spectra'][0]['rtime']-rt_ref) <= rt_stdev]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_comprehensive_stats_per_dataset(full_table_path, rt_tolerance, isotope_search_patterns, adduct_search_patterns, ion_mode):\n",
    "    '''construct khipus from given features and related information\n",
    "    \n",
    "    full_table_path: the path to the full feature table of current dataset\n",
    "    rt_tolerance: the retention time tolerance of current dataset. The tolerance is generated in step2 in elution_parameters_45studies.tsv\n",
    "    ion_mode: the ionization mode of current dataset\n",
    "    \n",
    "    returns: \n",
    "    list_khipus: khipu list from given feature list\n",
    "    all_assigned_fids: feature id list of the features being used in khipus\n",
    "    list_features: all feature list\n",
    "    '''\n",
    "    with contextlib.redirect_stdout(io.StringIO()):\n",
    "        _n, list_features = read_features_from_asari_table(open(full_table_path).read())\n",
    "        \n",
    "        for f in list_features:\n",
    "            f['representative_intensity'] = f['peak_area']\n",
    "        list_khipus, all_assigned_fids = peaklist_to_khipu_list(\n",
    "                                list_features, \n",
    "                                isotope_search_patterns=isotope_search_patterns, \n",
    "                                adduct_search_patterns=adduct_search_patterns,\n",
    "                                extended_adducts=[],    # not to confuse later analysis of ISF\n",
    "                                mz_tolerance_ppm=5,\n",
    "                                rt_tolerance=rt_tolerance,\n",
    "                                mode=ion_mode,\n",
    "                                charges=[1, 2, 3],\n",
    "                                )\n",
    "        # remaining_features = [f for f in list_features if f['id'] not in all_assigned_fids]\n",
    "    return export_empCpd_khipu_list(list_khipus), all_assigned_fids, list_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def explain_a_dataset_by_mz_deltas(list_khipus, remaining_features, isf_candidate_fragments, rt_stdev=0.613):\n",
    "    '''map the pairwise mass distance of the khipus and 'free' features to isf_candidate_fragments\n",
    "    \n",
    "    list_khipus: list of khipus\n",
    "    remaining_features: list of orphan features\n",
    "    isf_candidate_fragments: list of the most frequent delta mass values \n",
    "    rt_stdev: half window of rt tolerance\n",
    "    \n",
    "    return:\n",
    "    explained_khipu_ids: list of explained khipu ids\n",
    "    explained_feature_ids: list of explained feature ids\n",
    "    delta_values_used: list of delta mz values used for explanation\n",
    "    '''\n",
    "    def mz_delta_in_list(mz, mlist, max_diff=0.0005, ppm=5):\n",
    "        '''check if the given mz value is in given mz list(meet the requirement of certain number or ppm)\n",
    "        \n",
    "        mz: a float number of m/z delta value\n",
    "        mlist: a list of m/z value\n",
    "        max_diff: fixed number tolerance\n",
    "        ppm: ppm tolerance\n",
    "        \n",
    "        return: a boolean value indicating if the given mz sits in the window of any mz value in the given mlist.\n",
    "        '''\n",
    "        r = False\n",
    "        if mz > max_diff:\n",
    "            deltas = sorted([abs(x-mz) for x in mlist])\n",
    "            if deltas[0] <= max_diff or deltas[0]/mz < ppm*1e-6:\n",
    "                r = True\n",
    "        return r \n",
    "    \n",
    "    explained_khipu_ids, explained_feature_ids, delta_values_used = [], [], []\n",
    "\n",
    "    # iterate through given khipu list\n",
    "    for ii in range(len(list_khipus)-1):\n",
    "        # get rtime of current khipu\n",
    "        rt_ref = list_khipus[ii]['MS1_pseudo_Spectra'][0]['rtime']\n",
    "        # get mz of M0 feature in current khipu\n",
    "        base_mz = get_M0(list_khipus[ii]['MS1_pseudo_Spectra'])['mz']\n",
    "        # get list of khipus whose mass value is bigger than current one\n",
    "        khipus_in_rtwindow = get_khipus_in_rtwindow(\n",
    "            list_khipus[ii+1:], \n",
    "            rt_ref, \n",
    "            rt_stdev)\n",
    "        # iterate through the khipus in rtime window to get whose delta to given one matching isf_candidate_fragments\n",
    "        for k in khipus_in_rtwindow:\n",
    "            _d = list_khipus[ii]['neutral_formula_mass']-k['neutral_formula_mass']\n",
    "            if mz_delta_in_list(_d, isf_candidate_fragments):\n",
    "                explained_khipu_ids.append(k['interim_id'])\n",
    "                delta_values_used.append((_d, k['interim_id'], rt_ref-get_M0(k['MS1_pseudo_Spectra'])['rtime']))\n",
    "        \n",
    "        # iterate through the features in rtime window to get whose delta to given one matching isf_candidate_fragments\n",
    "        features_in_rtwindow = get_features_in_rtwindow(\n",
    "            remaining_features, \n",
    "            rt_ref, \n",
    "            rt_stdev)\n",
    "        for f in features_in_rtwindow:\n",
    "            _d = base_mz - f['mz']\n",
    "            if mz_delta_in_list(_d, isf_candidate_fragments):\n",
    "                explained_feature_ids.append(f['id'])\n",
    "                delta_values_used.append((_d, f['id'], rt_ref-f['rtime']))\n",
    "                \n",
    "    return explained_khipu_ids, explained_feature_ids, delta_values_used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_match_ms2_from_mzs_in_rtbin(mzs_in_rtbin, ms2_fragments, limit_ppm=5):\n",
    "    '''returns ms2 fragments that are matched in mzs_in_rtbin\n",
    "    \n",
    "    mzs_in_rtbin: list of mz values in a certain rt bin. Ex, [81.0178, 83.0863, 75.0996, 71.05, 72.0715]\n",
    "    ms2_fragments: list of tuple (intenisty, mz). Ex. [(100.0, 104.05261), (73.74, 56.04967), (63.76, 133.03153), (26.88, 61.01076), (25.4, 102.05479)]\n",
    "    \n",
    "    note: ms2_precursor and khipu M0 should already match before this.\n",
    "    \n",
    "    return: list of matched mz values\n",
    "    '''\n",
    "    found = []\n",
    "    if mzs_in_rtbin and ms2_fragments:\n",
    "        for x in mzs_in_rtbin:\n",
    "            for mz in ms2_fragments:\n",
    "                if abs(mz-x['mz']) < 0.000001*limit_ppm*mz:\n",
    "                    found.append((mz, x['id']))\n",
    "    return found\n",
    "\n",
    "def explain_a_dataset_byMS2(all_features, ms2_tree, rt_stdev, limit_ppm=5):\n",
    "    '''given a dataset, map the precursor and related ms2 peaks to ms2 tree\n",
    "    \n",
    "    all_features: list of features in metDataModel format. Ex. \n",
    "        {'id_number': 'F1',\n",
    "        'id': 'F1',\n",
    "        'mz': 70.0066,\n",
    "        'rtime': 540.23,\n",
    "        'apex': 540.23,\n",
    "        'left_base': 539.97,\n",
    "        'right_base': 541.3,\n",
    "        'parent_masstrack_id': '0',\n",
    "        'peak_area': '132716',\n",
    "        'cSelectivity': '0.27',\n",
    "        'goodness_fitting': '0.56',\n",
    "        'snr': '75',\n",
    "        'detection_counts': '4',\n",
    "        'representative_intensity': '132716'}\n",
    "    \n",
    "    ms2_tree: the dict built by function: `build_centurion_tree` from ms2 spectra list\n",
    "    example ms2_tree: {20908: [{'mz': 209.081,\n",
    "        'rtime': 0,\n",
    "        'name': 'Pyrenocin A - NCGC00169582-02_C11H12O4_1H-2-Benzopyran-1-one, 3,4-dihydro-6-hydroxy-8-methoxy-3-methyl-',\n",
    "        'peaks': [(100.0, 163.075516),\n",
    "        (96.239927, 191.070282),\n",
    "        (26.604602, 103.053802),\n",
    "        (19.662868, 135.080414),\n",
    "        (18.420266, 148.05191)]}]}\n",
    "        \n",
    "    note: example result from test_match_ms2: [191.070282]\n",
    "    \n",
    "    return:\n",
    "    _have_precursors: the list of feature id who has precursor matched\n",
    "    matched: the tuple containing matched feature id, precursor name and the delta: (precursor's mz - ms2 peak's mz)\n",
    "    '''   \n",
    "    matched, _have_precursors = [], []\n",
    "    for ff in all_features:\n",
    "        in_rtwindow = get_features_in_rtwindow(all_features, ff['rtime'], rt_stdev)\n",
    "        in_rtwindow = [x for x in in_rtwindow if x['mz'] < ff['mz']*(1+limit_ppm*1e-6)]\n",
    "        # find matched precursor\n",
    "        precursors = find_all_matches_centurion_indexed_list(ff['mz'], ms2_tree, limit_ppm=limit_ppm)\n",
    "        if precursors:\n",
    "            _have_precursors.append(ff['id_number'])\n",
    "        for sp in precursors:\n",
    "            matched_ms2_mzs = find_match_ms2_from_mzs_in_rtbin(in_rtwindow, [x[1] for x in sp['peaks']], limit_ppm)\n",
    "            \n",
    "            if matched_ms2_mzs:\n",
    "                # _deltas = [sp['mz']-x for x in matched_ms2_mzs] # delta between ms2 peaks and precursors\n",
    "                matched.append((ff['id_number'], sp['name'], matched_ms2_mzs))\n",
    "                \n",
    "    return _have_precursors, matched\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading MoNA MS2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import logging\n",
    "logging.getLogger(\"matchms\").setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_from_mona(path):\n",
    "    '''read from mona ms2 file from a given path\n",
    "    \n",
    "    path: the path to mona .msp file\n",
    "    \n",
    "    return: the inchikey-spectra pair.\n",
    "    '''\n",
    "    # reused from JM\n",
    "    spectral_registry = {}\n",
    "    total = 0\n",
    "    for x in tqdm.tqdm(load_from_msp(path)):\n",
    "        try:\n",
    "            inchikey = x.metadata_dict()['inchikey']\n",
    "            if inchikey:\n",
    "                if inchikey not in spectral_registry:\n",
    "                    spectral_registry[inchikey] = []\n",
    "                spectral_registry[inchikey].append(x)\n",
    "                total += 1\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    print(\"MS2 #: \", str(len(spectral_registry)), \" Compounds with \", str(total), \" MS2 Spectra\")\n",
    "    return spectral_registry\n",
    "\n",
    "def extract_ms2_spectrum(sp, N=5):\n",
    "    '''get precursor, name and top N (intensity, mz) from given ms2 spectrum\n",
    "\n",
    "    sp: given spectrum to extract\n",
    "    N: top N intensity:mz pair to extract\n",
    "    \n",
    "    return: (precursor mz, compound name, (intensity, mz) list). Ex.\n",
    "            (248.0585,\n",
    "            'Forchlorfenuron',\n",
    "            [(100.0, 111.0553),\n",
    "            (95.390586, 129.0214),\n",
    "            (17.257158, 93.0448),\n",
    "            (11.163815, 155.0007),\n",
    "            (10.442742, 137.0346)])\n",
    "    '''\n",
    "    _d = sp.metadata_dict()\n",
    "    _precursor, _name = _d['precursor_mz'], _d['compound_name']\n",
    "    imz = zip(sp.peaks.intensities, sp.peaks.mz)\n",
    "    imz = [x for x in imz if x[1] < _precursor - 0.01 and x[0] > 0.1] # excluding _precursor and small peaks\n",
    "    return _precursor, _name, sorted(imz, reverse=True)[:N]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13973it [00:05, 2530.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MS2 #:  13973  Compounds with  13973  MS2 Spectra\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9184it [00:03, 2848.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MS2 #:  9184  Compounds with  9184  MS2 Spectra\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "spectral_registry_pos = load_from_mona('../MoNA_MS2/filtered_MoNA-export-LC-MS-MS_Positive_Mode.msp')\n",
    "spectral_registry_neg = load_from_mona('../MoNA_MS2/filtered_MoNA-export-LC-MS-MS_Negative_Mode.msp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13670 spectra are found with precursors.\n",
      "9074 spectra are found with precursors.\n"
     ]
    }
   ],
   "source": [
    "# ms2List is usable MoNA MS/MS compounds\n",
    "ms2List_pos, no_precursor_pos = [], []\n",
    "for sp in spectral_registry_pos.values(): \n",
    "    try:\n",
    "        ms2List_pos.append(extract_ms2_spectrum(sp[0])) \n",
    "    except KeyError:\n",
    "        no_precursor_pos.append(sp[0])\n",
    "        \n",
    "print(f'{len(ms2List_pos)} spectra are found with precursors.')\n",
    "\n",
    "ms2List_neg, no_precursor_neg = [], []\n",
    "for sp in spectral_registry_neg.values(): \n",
    "    try:\n",
    "        ms2List_neg.append(extract_ms2_spectrum(sp[0])) \n",
    "    except KeyError:\n",
    "        no_precursor_neg.append(sp[0])\n",
    "        \n",
    "print(f'{len(ms2List_neg)} spectra are found with precursors.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "ms2_tree_pos = build_centurion_tree([{'mz': x[0], 'rtime': 0, 'name': x[1], 'peaks': x[2]} for x in ms2List_pos])\n",
    "ms2_tree_neg = build_centurion_tree([{'mz': x[0], 'rtime': 0, 'name': x[1], 'peaks': x[2]} for x in ms2List_neg])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Runinng Batches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tof_datasets = [x.rstrip() for x in open('selected_16_tof_datasets.txt').readlines()]\n",
    "pos_tof_datasets = [x for x in tof_datasets if 'pos' in x]\n",
    "neg_tof_datasets = [x for x in tof_datasets if 'neg' in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_rtwindow = {}\n",
    "for line in open('elution_parameters_16studies_tof.tsv').readlines()[1:]:\n",
    "    a = line.rstrip().split('\\t')\n",
    "    dict_rtwindow[a[0]] = float(a[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14,\n",
       " (28.0312,\n",
       "  '28.0312\\t550\\t28.0312\\t[\\'28.0313\\', \\'± C2H4, natural alkane chains such as fatty acids\\', \"{\\'C\\': 2, \\'H\\': 4}\"]'))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidate_fragments = '''14.0155\t792\t14.0155\t['14.01565', \"± CH2, alkane chains, waxes, fatty acids, methylation; or '-[C3H6ON] <-> -[C2H4ON], acrylamide versus iodoacetamide in cysteine alkylation (gels)\", \"{'C': 1, 'H': 2}\"]\n",
    "18.0104\t780\t18.0104\t['-18.010565', 'H2O', \"{'H': -2, 'O': -1}\"]\n",
    "2.0156\t634\t2.0156\t['2.01565', '± 2H, opening or forming of double bond', \"{'H': 2}\"]\n",
    "28.0312\t550\t28.0312\t['28.0313', '± C2H4, natural alkane chains such as fatty acids', \"{'C': 2, 'H': 4}\"]\n",
    "15.9948\t420\t15.9948\t['15.99492', '± O, e.g. oxidation/reduction', \"{'O': 1}\"]\n",
    "17.0264\t404\t17.0264\t['-17.026549', 'NH3', \"{'N': -1, 'H': -3}\"]\n",
    "26.0155\t392\t26.0155\t[' C2H2']\n",
    "27.9948\t385\t27.9948\t['27.99492', '± CO', \"{'C': 1, 'O': 1}\"]\n",
    "32.026\t311\t32.0261\t['32.026215', 'MeOH', \"{'C': 1, 'H': 4, 'O': 1}\"]\n",
    "42.0104\t301\t42.0104\t['42.01057', '± COCH2', \"{'C': 2, 'O': 1, 'H': 2}\"]\n",
    "67.9872\t295\t67.9873\t['67.987424', 'NaCOOH', \"{'C': 1, 'O': 2, 'Na': 1, 'H': 1}\"]\n",
    "13.9791\t287\t13.9791\t['13.97927', 'O <-> 2H, e.g. Oxidation follwed by H2O elimination', \"{'H': -2, 'O': 1}\"]\n",
    "42.0468\t278\t42.0468\t['42.04695', '± C3H6, propylation', \"{'C': 3, 'H': 6}\"]\n",
    "46.0053\t277\t46.0053\t['-46.005479', 'H2O+CO', \"{'C': -1, 'H': -2, 'O': -2}\"]\n",
    "'''\n",
    "candidate_fragments = [\n",
    "    (float(x.split()[0]), x) for x in candidate_fragments.splitlines()\n",
    "]\n",
    "isf_candidate_fragments = [x[0] for x in candidate_fragments]\n",
    "len(candidate_fragments), candidate_fragments[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tally_pos = []\n",
    "for f in pos_tof_datasets:\n",
    "    list_khipus, all_assigned_fids, list_features = get_comprehensive_stats_per_dataset(\n",
    "        f'../input_data_tof/{f}/full_feature_table.tsv', \n",
    "        dict_rtwindow[f], \n",
    "        isp_pos,\n",
    "        asp_pos,\n",
    "        'pos')\n",
    "    \n",
    "    # sort to make sure we are getting in-source fragments\n",
    "    remaining_features = [f for f in list_features if f['id'] not in all_assigned_fids]\n",
    "        \n",
    "    list_khipus = sorted(list_khipus, key=lambda x: x['neutral_formula_mass'], reverse=True)\n",
    "    \n",
    "    # by isf_candidate_fragments\n",
    "    explained_khipu_ids, explained_feature_ids, delta_values_used = explain_a_dataset_by_mz_deltas(\n",
    "        list_khipus, remaining_features, isf_candidate_fragments, \n",
    "        rt_stdev=dict_rtwindow[f]\n",
    "        )\n",
    "    \n",
    "    # # by MoNA MS2\n",
    "    have_precursors, matched2 = explain_a_dataset_byMS2(\n",
    "        list_features, ms2_tree_pos, rt_stdev=dict_rtwindow[f])\n",
    "    delta_values_ms2 = []\n",
    "    for x in matched2:\n",
    "        delta_values_ms2 += x[2]\n",
    "\n",
    "    tally_pos.append(\n",
    "        {\n",
    "            'study': f,\n",
    "            'num_khipus': len(list_khipus),\n",
    "            'num_features':  len(list_features),\n",
    "            'mzdelta_explained_khipus': len(set(explained_khipu_ids)), \n",
    "            'mzdelta_explained_features': len(set(explained_feature_ids)),\n",
    "            'freq_delta_values_used': delta_values_used,\n",
    "            'have_precursors': len(have_precursors),\n",
    "            'ms2_explained_features': len(matched2),\n",
    "            'delta_values_ms2': delta_values_ms2,\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('isfExplained_result_tally_pos.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(tally_pos, f,  ensure_ascii=False, indent=2) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code is a bit slow runinng in jupyter notebook. Modified it to run_stats_by_batches_pos.py, and then assemble the result below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "tally_pos = []\n",
    "for pos_res in os.listdir('output/tof/12172024_2/pos'):\n",
    "    tally_pos.append(json.load(open('output/tof/12172024_2/pos/' + pos_res, 'r')))\n",
    "print(len(tally_pos))\n",
    "with open('isfExplained_result_tally_pos_tof_12172024.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(tally_pos, f,  ensure_ascii=False, indent=2) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Negative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tally_neg = []\n",
    "for f in neg_tof_datasets:\n",
    "    list_khipus, all_assigned_fids, list_features = get_comprehensive_stats_per_dataset(\n",
    "        f'../input_data_tof/{f}/full_feature_table.tsv', \n",
    "        dict_rtwindow[f], \n",
    "        isp_neg,\n",
    "        asp_neg,\n",
    "        'neg')\n",
    "    \n",
    "    # sort to make sure we are getting in-source fragments\n",
    "    remaining_features = [f for f in list_features if f['id'] not in all_assigned_fids]\n",
    "\n",
    "    list_khipus = sorted(list_khipus, key=lambda x: x['neutral_formula_mass'], reverse=True)\n",
    "    \n",
    "    # by isf_candidate_fragments\n",
    "    explained_khipu_ids, explained_feature_ids, delta_values_used = explain_a_dataset_by_mz_deltas(\n",
    "        list_khipus, remaining_features, isf_candidate_fragments, \n",
    "        rt_stdev=dict_rtwindow[f]\n",
    "        )\n",
    "    \n",
    "    # # by MoNA MS2\n",
    "    have_precursors, matched2 = explain_a_dataset_byMS2(\n",
    "        list_features, ms2_tree_neg, rt_stdev=dict_rtwindow[f])\n",
    "    delta_values_ms2 = []\n",
    "    for x in matched2:\n",
    "        delta_values_ms2 += x[2]\n",
    "\n",
    "    tally_neg.append(\n",
    "        {\n",
    "            'study': f,\n",
    "            'num_khipus': len(list_khipus),\n",
    "            'num_features':  len(list_features),\n",
    "            'mzdelta_explained_khipus': len(set(explained_khipu_ids)), \n",
    "            'mzdelta_explained_features': len(set(explained_feature_ids)),\n",
    "            'freq_delta_values_used': delta_values_used,\n",
    "            'have_precursors': len(have_precursors),\n",
    "            'ms2_explained_features': len(matched2),\n",
    "            'delta_values_ms2': delta_values_ms2,\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('isfExplained_result_tally_neg.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(tally_neg, f,  ensure_ascii=False, indent=2) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above code is a bit slow runinng in jupyter notebook. Modified it to run_stats_by_batches_neg.py, and then assemble the result below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "tally_neg = []\n",
    "for neg_res in os.listdir('output/tof/12172024_2/neg'):\n",
    "    tally_neg.append(json.load(open('output/tof/12172024_2/neg/' + neg_res, 'r')))\n",
    "print(len(tally_neg))\n",
    "with open('isfExplained_result_tally_neg_tof_12172024.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(tally_neg, f,  ensure_ascii=False, indent=2) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ST002826_HILICpos__ppm25_1031121621 \n",
      " 4400 40 149\n",
      "MTBLS1133_RPpos_B2_ppm25_103113407 \n",
      " 48168 73 174\n",
      "ST000726_RPpos__ppm25_103113299 \n",
      " 37840 102 333\n",
      "ST001217_HILICpos__ppm25_103111503 \n",
      " 7489 29 70\n",
      "MTBLS718_RPpos_LPOS_B3_ppm25_1031121232 \n",
      " 20974 51 69\n",
      "ST002711_HILICpos_467535 Lipkin posHILIC 6530b_B7_ppm25_1031114314 \n",
      " 8015 38 84\n",
      "MTBLS718_HILICpos_HPOS_B1_ppm25_1031115857 \n",
      " 41783 185 407\n",
      "ST000046_HILICpos__ppm25_1031113822 \n",
      " 4173 24 82\n",
      "ST001828_RPpos_POS_ppm25_1031131529 \n",
      " 133502 951 1209\n",
      "ST001217_RPpos__ppm25_1031115140 \n",
      " 52472 286 368\n",
      "ST002700_RPneg_466506 Lipkin negCSH 6550_B8_ppm25_103112379 \n",
      " 26092 243 336\n",
      "ST000046_RPneg__ppm25_1031114022 \n",
      " 2171 11 65\n",
      "ST002711_HILICneg_467535 Lipkin negHILIC 6550_B4_ppm25_1031115431 \n",
      " 20303 263 316\n",
      "MTBLS718_RPneg_LNEG_B2_ppm25_1031122629 \n",
      " 5751 54 154\n",
      "ST001828_RPneg_NEG_ppm25_1031133743 \n",
      " 84791 428 454\n",
      "ST000726_RPneg__ppm25_1031133359 \n",
      " 22350 64 119\n"
     ]
    }
   ],
   "source": [
    "for x in tally_pos + tally_neg:\n",
    "    print(x['study'], '\\n', x['num_features'], x['mzdelta_explained_features'], x['ms2_explained_features'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
